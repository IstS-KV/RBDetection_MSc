{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb5b13e-7adf-4e9b-ba66-6d1f459fe989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import json\n",
    "from ismember import ismember\n",
    "import random\n",
    "import pyedflib\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e20b11c-aa03-4ae2-ac1d-30f68a52de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is dedicated to convert ground truth labels of all 3 datasets into 30 seconds w.r.t. AASM guidelines\n",
    "# CAP, 30 sec, R&K. Labels are separated into two files (two halfs of the recordings)\n",
    "\n",
    "# WESA dataset, 20sec, AASM. REM labeled as 5. Also contains 6 as an indicator of end of file or bad channel. \n",
    "# Sometimes I meet 4 in the file (just a couple of times), which is there by mistake. In this case, I convert it to NREM...\n",
    "\n",
    "# MASS dataset \n",
    "# SS1 --> no changes required (maybe also convert to .txt)\n",
    "# SS2 --> 20sec, R&K\n",
    "# SS3 --> no changes required (maybe also convert to .txt)\n",
    "# SS4 --> 20sec, R&K\n",
    "# SS5 -->20sec, R&K\n",
    "# Important that in MASS dtaset there are epochs that labeled as '?', need to check what it means\n",
    "# Leave '?' for now\n",
    "\n",
    "# Sleep Stages\n",
    "# Wake --> 0\n",
    "# N1 --> 1\n",
    "# N2 --> 2\n",
    "# N3 --> 3\n",
    "# REM --> 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d830316-fc20-4f72-9d55-3c09bc969a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_gt_processing(pat, gt_files, save_path):\n",
    "    # extract ground truth\n",
    "    gt = []\n",
    "    gt = [x for x in gt_files if x.endswith(str(pat) + \".mat\")]\n",
    "\n",
    "    hypno0 = scipy.io.loadmat(gt[0])\n",
    "    hypno = np.array(hypno0['hyp'][:,0])\n",
    "    \n",
    "    # convert true labels to the AASM system\n",
    "    for jj in range(len(hypno)):\n",
    "        if hypno[jj] == 4:\n",
    "            hypno[jj] = 3\n",
    "        elif hypno[jj] == 5:\n",
    "            hypno[jj] = 4\n",
    "\n",
    "    hypno = hypno.flatten()\n",
    "    hypno_new = [str(x) for x in hypno]\n",
    "\n",
    "    # save new ground truth in txt files\n",
    "    with open(save_path, 'w') as f:   \n",
    "        for items in hypno_new:\n",
    "            f.write('%s\\n' %items)\n",
    "\n",
    "def convert_20s_to_30s(file):\n",
    "    # lists to store the name of the file and expert labels that were used for gt\n",
    "    name = []\n",
    "    exp = []\n",
    "    labeled_exp = []\n",
    "    label_30s = []\n",
    "    # list to store the cases where all three 20sec windows are different\n",
    "    change = []\n",
    "    \n",
    "    # load the file\n",
    "    f_load = scipy.io.loadmat(file)\n",
    "\n",
    "    for jj in f_load.keys():\n",
    "        if \"sleepStage_score\" in jj:\n",
    "            labeled_exp.append(jj)\n",
    "\n",
    "    if len(labeled_exp) == 1:\n",
    "        key = labeled_exp[0]\n",
    "    else:\n",
    "        v = random.randint(0,len(labeled_exp)-1)\n",
    "        key = labeled_exp[v]\n",
    "        \n",
    "    label_20s = f_load[key][0]\n",
    "    total_len = (len(label_20s)-1)*20\n",
    "\n",
    "    new_num_epochs = np.round(total_len/30)\n",
    "\n",
    "    # last value is 6, which indicated eof and i don't take in account (WESA)\n",
    "    for jjj in range(0, len(label_20s)-1, 3):\n",
    "        if jjj+3 <= len(label_20s)-2:\n",
    "            label_temp = label_20s[jjj:jjj+3]\n",
    "        else:\n",
    "            eof = len(label_20s)-1\n",
    "            label_temp = label_20s[jjj:eof]\n",
    "\n",
    "        # store information if all 3 stages in a row are labeled differently (rather exception or artifact) \n",
    "        if np.sum(np.diff(label_temp)) > 1:\n",
    "            change.append(jjj)\n",
    "\n",
    "        if len(label_temp) == 3:\n",
    "            label_30s.append(label_temp[0])\n",
    "            label_30s.append(label_temp[2])\n",
    "        elif len(label_temp) == 0:\n",
    "            print('Done')\n",
    "        else:\n",
    "            label_30s.append(label_temp[0])\n",
    "            \n",
    "    assert(len(label_30s) == new_num_epochs)\n",
    "\n",
    "    return key, change, label_30s\n",
    "\n",
    "def edf_to_txt(file):\n",
    "    data = mne.read_annotations(file)\n",
    "    stages = data.description\n",
    "    onset = data.onset[0]\n",
    "\n",
    "    for jj in range(len(stages)):\n",
    "        stages[jj] = stages[jj].replace('Sleep stage ', '')\n",
    "\n",
    "    return onset, stages \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67a8e40",
   "metadata": {},
   "source": [
    "CAP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e94adbd-ccfe-4fe4-a272-6924573bd708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAP HC\n",
    "# extract mat files with ground truth\n",
    "gt_path = \"Path\\\\to\\\\load\\\\the\\\\data\"\n",
    "gt_files = glob.glob(gt_path)\n",
    "\n",
    "# create list of rbd patients that exist in CAP dataset\n",
    "hc_pat = [\"n1\", \"n2\", \"n3\", \"n5\", \"n10\", \"n11\", ]\n",
    "\n",
    "for j in range(len(hc_pat)):\n",
    "\n",
    "    pat = hc_pat[j]\n",
    "    save_path = os.path.join(\"Path\\\\to\\\\store\\\\the\\\\new\\\\30secodEpochs\", f'{pat}.txt')\n",
    "\n",
    "    cap_gt_processing(pat, gt_files, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f7b58-f6d1-4c79-b37c-524e66550aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAP\n",
    "# extract mat files with ground truth\n",
    "gt_path = \"Path\\\\to\\\\load\\\\the\\\\data\"\n",
    "gt_files = glob.glob(gt_path)\n",
    "\n",
    "# create list of rbd patients that exist in CAP dataset\n",
    "rbd_pat = [\"rbd1\", \"rbd2\", \"rbd3\", \"rbd4\", \"rbd5\", \"rbd6\", \"rbd7\", \"rbd8\", \"rbd9\", \"rbd10\", \"rbd12\",\n",
    "           \"rbd13\", \"rbd14\", \"rbd15\", \"rbd16\", \"rbd17\", \"rbd18\", \"rbd19\", \"rbd20\", \"rbd21\", \"rbd22\"]\n",
    "\n",
    "for j in range(len(rbd_pat)):\n",
    "\n",
    "    pat = rbd_pat[j]\n",
    "    save_path = os.path.join(\"Path\\\\to\\\\store\\\\the\\\\new\\\\30secodEpochs\", f'{pat}.txt')\n",
    "\n",
    "    cap_gt_processing(pat, gt_files, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21f3a4b",
   "metadata": {},
   "source": [
    "WESA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba6a69e-a545-4ddf-9081-7f217494582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WESA\n",
    "path_wesa = \"Path\\\\to\\\\load\\\\the\\\\data\"\n",
    "path_to_save = \"Path\\\\to\\\\store\\\\the\\\\new\\\\30secodEpochs\"\n",
    "sham_path = os.path.join(path_wesa, 'sham\\\\*.mat')\n",
    "verum_path = os.path.join(path_wesa, 'verum\\\\*.mat')\n",
    "\n",
    "sham_files = glob.glob(sham_path)\n",
    "verum_files = glob.glob(verum_path)\n",
    "\n",
    "experts = [\"sleepStage_score_E1\", \"sleepStage_score_E2\", \"sleepStage_score_E3\", \"sleepStage_score_E4\"]\n",
    "\n",
    "# The file can contain labels for 1 or more experts. In case of 1 expert it is clear. If more than one, randomly of the experts was chosen. \n",
    "name = []\n",
    "exp = []\n",
    "jumps = []\n",
    "\n",
    "for j in range(len(verum_files)):\n",
    "\n",
    "    # read a file\n",
    "    file = verum_files[j]\n",
    "    # only for WESA dataset\n",
    "    idx = verum_files[0].find('WESA_EEG')\n",
    "    wesa_name = file[idx-1:-4]\n",
    "\n",
    "    expert, change, label_30s = convert_20s_to_30s(file)\n",
    "\n",
    "    jumps.append(file)\n",
    "    jumps.append(change)\n",
    "    name.append(file)\n",
    "    exp.append(expert)\n",
    "    \n",
    "    # WESA\n",
    "    # check if there are any 4 (a mistake) and convert to 3 then \n",
    "    # convert 5 to 4 (REM)\n",
    "\n",
    "    for i in range(len(label_30s)):\n",
    "        if label_30s[i] == 4:\n",
    "            label_30s[i] = 3\n",
    "        elif label_30s[i] == 5:\n",
    "            label_30s[i] = 4\n",
    "        elif label_30s[i] == 6:\n",
    "            print('There is 6 in the file')\n",
    "    \n",
    "    label_30s_new = [str(x) for x in label_30s]\n",
    "\n",
    "    # save new ground truth in txt files\n",
    "    # np.savetxt(save_path, hypno_new, delimiter = ',')\n",
    "    with open(path_to_save + f\"verum\\\\{wesa_name}.txt\", 'w') as f: \n",
    "        for items in label_30s_new:\n",
    "            f.write('%s\\n' %items)\n",
    "\n",
    "# save a list of experts whose scores were used as gt to .txt file\n",
    "with open(path_to_save + \"exp_info_verum.txt\", \"w\")as f:\n",
    "    for jj in range(len(name)):\n",
    "        f.write('%s, %s\\n' %(name[jj], exp[jj]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa88b4e",
   "metadata": {},
   "source": [
    "MASS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881567a0-302c-4eab-95a5-f644a968d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MASS SS1 and SS3\n",
    "path = \"Path\\\\to\\\\load\\\\the\\\\data\"\n",
    "gt_f = glob.glob(path)\n",
    "\n",
    "path_to_save = \"Path\\\\to\\\\store\\\\the\\\\new\\\\30secodEpochs\"\n",
    "folder = 'hypno_gt\\\\'\n",
    "symbols = len(folder)\n",
    "\n",
    "for jj in range(len(gt_f)):\n",
    "    file = gt_f[jj]\n",
    "    ix = file.find('hypno_gt\\\\')\n",
    "\n",
    "    # extract stages\n",
    "    onset_time, stages = edf_to_txt(file)\n",
    "\n",
    "    # N1, N2, N3 are labeled as 1, 2, 3. Wake is labeled as W (change to 0)  and REM is labeled as R (change to 4). '?' leave for now\n",
    "    for jjj in range(len(stages)):\n",
    "        if stages[jjj] == 'W':\n",
    "            stages[jjj] = '0'\n",
    "        elif stages[jjj] == 'R':\n",
    "            stages[jjj] = '4'\n",
    "\n",
    "    with open(path_to_save + f\"\\\\{file[ix+symbols:-4]}.txt\", 'w') as f:  \n",
    "        f.write('%s %s\\n' %('Onset time is ', onset_time))\n",
    "        for items in stages:\n",
    "            f.write('%s\\n' %items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c811b-2176-4740-a67f-031ca9f0ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MASS SS2, SS4 and SS5\n",
    "path = \"Path\\\\to\\\\load\\\\the\\\\data\"\n",
    "gt_f = glob.glob(path)\n",
    "\n",
    "path_to_save = \"Path\\\\to\\\\store\\\\the\\\\new\\\\30secodEpochs\"\n",
    "folder = 'hypno_gt\\\\'\n",
    "symbols = len(folder)\n",
    "\n",
    "\n",
    "change = []\n",
    "\n",
    "for jj in range(len(gt_f)):\n",
    "    label_30s = []\n",
    "    \n",
    "    file = gt_f[jj]\n",
    "    ix = file.find('hypno_gt\\\\')\n",
    "\n",
    "    # extract stages\n",
    "    onset_time, label_20s = edf_to_txt(file)\n",
    "\n",
    "    total_len = (len(label_20s))*20\n",
    "    new_num_epochs = np.round(total_len/30)\n",
    "\n",
    "    \n",
    "    for jjj in range(0, len(label_20s), 3):\n",
    "        if jjj+3 <= len(label_20s)-2:\n",
    "            label_temp = label_20s[jjj:jjj+3]\n",
    "        else:\n",
    "            eof = len(label_20s)\n",
    "            label_temp = label_20s[jjj:eof]\n",
    "\n",
    "        if len(label_temp) == 3:\n",
    "            label_30s.append(label_temp[0])\n",
    "            label_30s.append(label_temp[2])\n",
    "        elif len(label_temp) == 0:\n",
    "            print('Done')\n",
    "        else:\n",
    "            label_30s.append(label_temp[0])\n",
    "            \n",
    "    # N1, N2, N3 are labeled as 1, 2, 3. Wake is labeled as W (change to 0)  and ReM is labeled as R (change to 4). '?' leave for now\n",
    "    for ii in range(len(label_30s)):\n",
    "        if label_30s[ii] == 'W':\n",
    "            label_30s[ii] = '0'\n",
    "        elif label_30s[ii] == '4':\n",
    "            label_30s[ii] = '3'    \n",
    "        elif label_30s[ii] == 'R':\n",
    "            label_30s[ii] = '4'\n",
    "\n",
    "    with open(path_to_save + f\"\\\\{file[ix+symbols:-4]}.txt\", 'w') as f:   # sham, verum\n",
    "        f.write('%s %s\\n' %('Onset time is ', onset_time))\n",
    "        for items in label_30s:\n",
    "            f.write('%s\\n' %items)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
